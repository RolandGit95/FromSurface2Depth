\section{Results}

To quantify the reconstruction of the neural networks, we calculate the point wise absolute error between the predicted values of $u$ of the voxels and their true values. The errors are then averaged layer wise, that one gets a mean absolute error per predicted layer. In section \ref{sec:T} we show the results of several trained neural networks of the same type, where the input sequence length is varied. It is tested with the two regimes (A and B), where A has periodic dynamic and B show chaotic behaviour. The best model, considering our error measurement from this experiment, is then taken for further examination in the section afterwords, where the reconstruction target changes. Furthermore, its results are compared to another neural network, which is based on convolutions and a conditional random field.

\subsection{}\label{sec:T}

Figures:
\begin{itemize}
    \item Full 3d cube with prediction
    \item Gridplot, different T
    \item MAE comparison with different Depths
    \item Comparison with Sebastian's model
\end{itemize}

% Up to three levels of \textbf{subheading} are permitted. Subheadings should not be numbered.
%- Machine learning results: learning time, etc.
%- how deep can we look? (still needed: spatial correlation)

%\subsection{Data}
%-> Copy equations from master thesis
%-> 3d plots of dynamics (fig 4.2)
%-> further characterization of data?
%-> characteristic numbers (time, spatial, velocity)

%-> two parameter sets of barkley model
%-> Parameter sets used
%-> N initial conditions for both, example snapshots after transient
%-> some characterisation (periodic, see figure figPeriodic, chaotic as can be estimated from figure figchaotic)

%\subsection*{Machine Learning}

%(Machine learning) experiment used. Parameter, model, references, explanation via a figure



%\subsection*{Subsection}

%Example text under a subsection. Bulleted lists may be used where appropriate, e.g.


%\subsubsection*{Third-level section}
%Topical subheadings are allowed.